{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91ba5269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import csv\n",
    "import time\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9496d323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING SILVER VACUUM (Volume Scraper) ---\n",
      "-> Appending to existing file...\n",
      "\n",
      "\n",
      ">>> TARGETING: https://www.pakwheels.com/used-cars/search/-/mk_toyota/\n",
      "\n",
      "--- Processing Page 1 ---\n",
      "-> Found 25 cars.\n",
      "\n",
      "--- Processing Page 2 ---\n",
      "-> Found 26 cars.\n",
      "\n",
      "--- Processing Page 3 ---\n",
      "-> Found 25 cars.\n",
      "\n",
      "--- Processing Page 4 ---\n",
      "-> Found 26 cars.\n",
      "\n",
      "--- Processing Page 5 ---\n",
      "-> Found 26 cars.\n",
      "\n",
      "--- Processing Page 6 ---\n",
      "-> Found 26 cars.\n",
      "\n",
      "--- Processing Page 7 ---\n",
      "-> Found 31 cars.\n",
      "\n",
      "--- Processing Page 8 ---\n",
      "-> Found 31 cars.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- CONFIGURATION ---\n",
    "# NOTE: These URLs do NOT have the \"pakwheels-inspected\" filter. We want everything.\n",
    "TARGET_URLS = [\n",
    "    # \"https://www.pakwheels.com/used-cars/search/-/mk_honda/\",\n",
    "    \"https://www.pakwheels.com/used-cars/search/-/mk_toyota/\",\n",
    "    # \"https://www.pakwheels.com/used-cars/search/-/mk_suzuki/\", \n",
    "    # \"https://www.pakwheels.com/used-cars/search/-/mk_hyundai/\",\n",
    "    # \"https://www.pakwheels.com/used-cars/search/-/mk_kia/\"\n",
    "]\n",
    "\n",
    "OUTPUT_FILE = \"pakwheels_silver_data.csv\"\n",
    "MAX_PAGES_PER_URL = 20  # 20 Pages = ~500-600 cars per brand. This is the big haul.\n",
    "\n",
    "# --- SETUP CHROME ---\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "# options.add_argument(\"--headless\") # Optional: Enable this to run in background\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "def clean_text(text):\n",
    "    if not text: return \"N/A\"\n",
    "    return \" \".join(text.split())\n",
    "\n",
    "try:\n",
    "    print(f\"--- STARTING SILVER VACUUM (Volume Scraper) ---\")\n",
    "    \n",
    "    file_exists = os.path.isfile(OUTPUT_FILE)\n",
    "    \n",
    "    # Open in Append Mode\n",
    "    with open(OUTPUT_FILE, mode='a', newline='', encoding='utf-8') as file:\n",
    "        fieldnames = ['url', 'title_version', 'model_year', 'mileage', 'engine', 'transmission', 'fuel', 'price', 'description']\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        \n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "            print(\"-> New file created. Header written.\")\n",
    "        else:\n",
    "            print(\"-> Appending to existing file...\")\n",
    "        \n",
    "        for target_url in TARGET_URLS:\n",
    "            print(f\"\\n\\n>>> TARGETING: {target_url}\")\n",
    "            driver.get(target_url)\n",
    "            \n",
    "            page_count = 0\n",
    "            while page_count < MAX_PAGES_PER_URL:\n",
    "                page_count += 1\n",
    "                print(f\"\\n--- Processing Page {page_count} ---\")\n",
    "                \n",
    "                try:\n",
    "                    WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"well\")))\n",
    "                except:\n",
    "                    print(\"Timeout waiting for list. Moving on.\")\n",
    "                    break\n",
    "\n",
    "                # Harvest Links\n",
    "                ad_elements = driver.find_elements(By.CSS_SELECTOR, \"a.car-name\")\n",
    "                car_urls = list(set([ad.get_attribute(\"href\") for ad in ad_elements if ad.get_attribute(\"href\") and \"/used-cars/\" in ad.get_attribute(\"href\")]))\n",
    "                print(f\"-> Found {len(car_urls)} cars.\")\n",
    "\n",
    "                # Secure Next Page\n",
    "                try:\n",
    "                    next_btn = driver.find_element(By.CSS_SELECTOR, \"li.next_page a\")\n",
    "                    next_page_url = next_btn.get_attribute(\"href\")\n",
    "                except:\n",
    "                    next_page_url = None\n",
    "\n",
    "                # Visit Cars\n",
    "                for link in car_urls:\n",
    "                    # print(f\"Visiting: {link[-20:]}...\") # Optional: Comment out to reduce clutter\n",
    "                    try:\n",
    "                        driver.get(link)\n",
    "                        # We can reduce sleep slightly since we aren't loading heavy reports\n",
    "                        time.sleep(0.5) \n",
    "                        \n",
    "                        data = {\n",
    "                            'url': link, 'title_version': 'N/A', 'model_year': 'N/A', \n",
    "                            'mileage': 'N/A', 'engine': 'N/A', 'transmission': 'N/A', 'fuel': 'N/A',\n",
    "                            'price': 'N/A', 'description': 'N/A'\n",
    "                        }\n",
    "\n",
    "                        # SPECS (Icons Table)\n",
    "                        try: data['model_year'] = driver.find_element(By.XPATH, \"//span[contains(@class, 'year')]/following-sibling::p\").text.strip()\n",
    "                        except: pass\n",
    "                        try: data['mileage'] = driver.find_element(By.XPATH, \"//span[contains(@class, 'millage')]/following-sibling::p\").text.strip()\n",
    "                        except: pass\n",
    "                        try: data['fuel'] = driver.find_element(By.XPATH, \"//span[contains(@class, 'type')]/following-sibling::p\").text.strip()\n",
    "                        except: pass\n",
    "                        try: data['transmission'] = driver.find_element(By.XPATH, \"//span[contains(@class, 'transmission')]/following-sibling::p\").text.strip()\n",
    "                        except: pass\n",
    "                        \n",
    "                        # ENGINE (List)\n",
    "                        try:\n",
    "                            specs_list = driver.find_element(By.ID, \"scroll_car_detail\")\n",
    "                            items = specs_list.find_elements(By.TAG_NAME, \"li\")\n",
    "                            for i in range(len(items)-1):\n",
    "                                if \"Engine Capacity\" in items[i].text:\n",
    "                                    data['engine'] = items[i+1].text.strip(); break \n",
    "                        except: pass\n",
    "\n",
    "                        # TITLE & PRICE\n",
    "                        try: data['title_version'] = driver.find_element(By.TAG_NAME, \"h1\").text.strip()\n",
    "                        except: pass\n",
    "                        try: data['price'] = driver.find_element(By.CLASS_NAME, \"price-box\").text.strip()\n",
    "                        except: pass\n",
    "\n",
    "                        # DESCRIPTION\n",
    "                        try:\n",
    "                            header = driver.find_element(By.ID, \"scroll_seller_comments\")\n",
    "                            desc_div = header.find_element(By.XPATH, \"./following-sibling::div[1]\")\n",
    "                            clean_desc = desc_div.text.replace(\"Mention PakWheels.com when calling Seller to get a good deal\", \"\").strip()\n",
    "                            data['description'] = clean_text(clean_desc)\n",
    "                        except: pass\n",
    "                        \n",
    "                        writer.writerow(data)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "\n",
    "                if next_page_url:\n",
    "                    driver.get(next_page_url)\n",
    "                    time.sleep(2)\n",
    "                else:\n",
    "                    print(\"End of list.\")\n",
    "                    break\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"CRITICAL ERROR: {e}\")\n",
    "finally:\n",
    "    driver.quit()\n",
    "    print(\"Batch Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621e0dcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
