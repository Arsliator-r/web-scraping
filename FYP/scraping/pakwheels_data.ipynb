{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef63737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price: PKR 42.5lacsFinancing starts at PKR 105,535/MonthManaged by PakWheels\n",
      "Attempting to fetch description via Sibling Navigation...\n",
      "SUCCESS! Description found:\n",
      "PakWheels inspected car\n",
      "Inspection report attached\n",
      "Number plates available\n",
      "2nd Owner\n",
      "Token Tax not Paid\n",
      "Manufacture 2019\n",
      "Registered 2019\n",
      "Documents available\n",
      "2 keys available\n",
      "Mention PakWheels.com when calling Seller to get a good deal\n",
      "\n",
      "Report Link Found:\n",
      "https://www.pakwheels.com/carsure-reports/fc29c0979dd7ba6b0b7019856f397e35\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# --- 1. YOUR TASK: FILL IN THESE FOUR VALUES ---\n",
    "\n",
    "# Paste the full URL of the single ad (one that HAS a report).\n",
    "URL = \"https://www.pakwheels.com/used-cars/toyota-corolla-2019-for-sale-in-karachi-10838003\" \n",
    "\n",
    "# Replace with the exact class names you found.\n",
    "# e.g., \"price-value\", \"ad-description\", \"report-link-class\"\n",
    "PRICE_CLASS = \"price-box\"\n",
    "DESCRIPTION_CLASS = \"YOUR_DESCRIPTION_CLASS_HERE\"\n",
    "REPORT_LINK_CLASS = \"btn btn-light-blue fs16\" # This should be the class of the <a> tag\n",
    "\n",
    "# --- 2. THE SCRAPER CODE (No need to change) ---\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    response = requests.get(URL, headers=headers)\n",
    "    response.raise_for_status()     # Check if the request was successful\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # --- 3. EXTRACTING THE DATA ---\n",
    "\n",
    "    # Find the Price\n",
    "    price_element = soup.find(class_=PRICE_CLASS)\n",
    "    if price_element:\n",
    "        print(f\"Price: {price_element.get_text(strip=True)}\")\n",
    "    else:\n",
    "        print(f\"Could not find price with class: {PRICE_CLASS}\")\n",
    "\n",
    "    print(\"Attempting to fetch description via Sibling Navigation...\")\n",
    "\n",
    "    # 1. Find the Header using the ID from your screenshot\n",
    "    header_element = soup.find(id=\"scroll_seller_comments\")\n",
    "\n",
    "    if header_element:\n",
    "        # 2. \"Hop\" to the very next tag (the <div> in your screenshot)\n",
    "        description_div = header_element.find_next_sibling(\"div\")\n",
    "        \n",
    "        if description_div:\n",
    "            # We use 'strip=True' to clean up the extra spaces seen in the screenshot\n",
    "            clean_text = description_div.get_text(separator=\"\\n\", strip=True)\n",
    "            print(f\"SUCCESS! Description found:\\n{clean_text}\")\n",
    "        else:\n",
    "            print(\"Found the header, but there was no sibling div next to it.\")\n",
    "    else:\n",
    "        print(\"Could not find the header with ID 'scroll_seller_comments'.\")\n",
    "\n",
    "    # Find the Inspection Report Link\n",
    "    # We find the <a> tag with the class you provided\n",
    "    report_link_element = soup.find(\"a\", class_=REPORT_LINK_CLASS)\n",
    "    \n",
    "    if report_link_element and report_link_element.has_attr('href'):\n",
    "        # We extract the 'href' attribute, which is the URL\n",
    "        report_url = report_link_element['href']\n",
    "        \n",
    "        # We need to make sure it's a full URL\n",
    "        if not report_url.startswith(\"http\"):\n",
    "            report_url = \"https://www.pakwheels.com\" + report_url\n",
    "            \n",
    "        print(f\"\\nReport Link Found:\\n{report_url}\")\n",
    "    else:\n",
    "        print(f\"\\nCould not find report link with class: {REPORT_LINK_CLASS}\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error fetching the URL: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6ddac89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visiting report: https://www.pakwheels.com/carsure-reports/fc29c0979dd7ba6b0b7019856f397e35...\n",
      "SUCCESS! Overall Score Found: 8.0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# --- 1. FILL IN THE REPORT URL ---\n",
    "# Use the link from the ad you just found\n",
    "URL = report_url \n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    print(f\"Visiting report: {URL}...\")\n",
    "    response = requests.get(URL, headers=headers)\n",
    "    response.raise_for_status()\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "    # --- SMART SEARCH: FIND THE SCORE PATTERN ---\n",
    "    # We look for text that looks like \"8.5 / 10\" or \"9.2/10\"\n",
    "    # \\d+\\.\\d+ means \"number dot number\"\n",
    "    # \\s* means \"maybe some spaces\"\n",
    "    # / 10 means \"slash ten\"\n",
    "    score_pattern = re.compile(r\"(\\d+\\.\\d+)\\s*/\\s*10\")\n",
    "    \n",
    "    # We search the whole page text for this pattern\n",
    "    found_text = soup.find(string=score_pattern)\n",
    "\n",
    "    if found_text:\n",
    "        # If we find \"Overall Rating 9.2 / 10\", we extract just the \"9.2\"\n",
    "        match = score_pattern.search(found_text)\n",
    "        if match:\n",
    "            print(f\"SUCCESS! Overall Score Found: {match.group(1)}\")\n",
    "        else:\n",
    "            print(\"Found text with '/ 10' but couldn't extract the number.\")\n",
    "            print(f\"Found text: {found_text.strip()}\")\n",
    "            \n",
    "    else:\n",
    "        print(\"Could not find any text matching the pattern 'X.X / 10'\")\n",
    "        \n",
    "        # specific fallback for PakWheels structure if the regex fails\n",
    "        # Sometimes the score is just a number inside a specific generic box\n",
    "        print(\"Attempting fallback search...\")\n",
    "        rating_box = soup.find(class_=\"rating-value\") # Common class name guess\n",
    "        if rating_box:\n",
    "             print(f\"Fallback Score Found: {rating_box.get_text(strip=True)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec9a0da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
